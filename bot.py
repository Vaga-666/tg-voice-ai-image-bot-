import os
import logging
import requests
import tempfile
import speech_recognition as sr
from pathlib import Path  # üëà –î–æ–±–∞–≤–∏–ª–∏
from pydub import AudioSegment
from telegram import Update, Voice, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from gtts import gTTS
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()


# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("‚ùå –ü—Ä–æ–≤–µ—Ä—å TELEGRAM_TOKEN –∏ OPENAI_API_KEY –≤ key.env")

# OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(api_key=OPENAI_API_KEY)


# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("bot.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
async def generate_image(update: Update, context: ContextTypes.DEFAULT_TYPE, prompt: str = None):
    if prompt is None:
        prompt = update.message.text
    logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É: {prompt}")
    try:
        response = client.images.generate(prompt=prompt, n=1, size="512x512")
        image_url = response.data[0].url
        keyboard = InlineKeyboardMarkup([
            [InlineKeyboardButton("üîó –û—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", url=image_url)]
        ])
        await context.bot.send_photo(chat_id=update.effective_chat.id, photo=image_url,
                                     caption="üñºÔ∏è –í–æ—Ç —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å!", reply_markup=keyboard)
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")
        await context.bot.send_message(chat_id=update.effective_chat.id, text="‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice: Voice = update.message.voice
    file = await context.bot.get_file(voice.file_id)
    ogg_path = tempfile.mktemp(suffix=".ogg")
    wav_path = ogg_path.replace(".ogg", ".wav")

    try:
        await file.download_to_drive(ogg_path)
        sound = AudioSegment.from_ogg(ogg_path)
        sound.export(wav_path, format="wav")
    except:
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å.")
        return

    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(wav_path) as source:
            audio = recognizer.listen(source, phrase_time_limit=10)
            text = recognizer.recognize_google(audio, language="ru-RU")
            logger.info(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}")
        await update.message.reply_text(f"üé§ –í—ã —Å–∫–∞–∑–∞–ª–∏: {text}")
    except:
        await update.message.reply_text("üõë –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞.")
        return

    # –ö–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    if "—Ñ–æ—Ç–æ" in text.lower():
        photo_url = await fetch_real_photo(text)
        if photo_url:
            await context.bot.send_photo(chat_id=update.effective_chat.id, photo=photo_url, caption="üì∏ –§–æ—Ç–æ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞")
        else:
            await update.message.reply_text("‚ùå –§–æ—Ç–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    if "–∫–∞—Ä—Ç–∏–Ω–∫" in text.lower() or "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏" in text.lower():
        await generate_image(update, context, prompt=text)
        return

    # –û—Ç–≤–µ—Ç –æ—Ç AI
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": text}]
        )
        answer = response.choices[0].message.content.strip()
        await update.message.reply_text(f"üí¨ {answer}")  # ‚Üê —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
    except:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ AI.")
        return

    # –ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
    try:
        tts = gTTS(answer, lang="ru")
        ogg_reply = tempfile.mktemp(suffix=".ogg")
        tts.save("temp.mp3")
        sound = AudioSegment.from_mp3("temp.mp3")
        sound.export(ogg_reply, format="ogg", codec="libopus")
        await update.message.reply_voice(voice=open(ogg_reply, "rb"))  # ‚Üê –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
    except:
        await update.message.reply_text("üîá –ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.")

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! üëã –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ:\n\n"
        "üìù –¢–µ–∫—Å—Ç ‚Äî —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n"
        "üé§ –ì–æ–ª–æ—Å ‚Äî —è —Ä–∞—Å–ø–æ–∑–Ω–∞—é –µ–≥–æ –∏, –µ—Å–ª–∏ —Ç—ã –ø–æ–ø—Ä–æ—Å–∏—à—å –∫–∞—Ä—Ç–∏–Ω–∫—É, –Ω–∞—Ä–∏—Å—É—é –µ—ë üñºÔ∏è"
    )

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, generate_image))
    app.add_handler(MessageHandler(filters.VOICE, voice_handler))
    logger.info("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω.")
    app.run_polling()
